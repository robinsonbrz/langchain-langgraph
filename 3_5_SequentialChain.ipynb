{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true,
    "id": "vOISp5PYq4qi",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.document_loaders import TextLoader\n",
    "import yaml\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config.yaml', 'r') as config_file:\n",
    "    config = yaml.safe_load(config_file)\n",
    "os.environ['OPENAI_API_KEY'] = config['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai = ChatOpenAI(model_name='gpt-4o', temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar os documentos\n",
    "loader = TextLoader('base_conhecimento_britadeira.txt')\n",
    "documents = loader.load()\n",
    "# Carregar histórico de conversas \n",
    "historico_conversas = \"\"\"Cliente: Minha britadeira não liga. Chatbot: Você já verificou \n",
    "                         se a bateria está carregada e conectada corretamente?\"\"\"\n",
    "# Pergunta do cliente\n",
    "pergunta = \"Minha britadeira não liga. Eu já veriquei e a bateria está carregada e conectada corretamente\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {\n",
    "    \"context\": \"\\n\".join(doc.page_content for doc in documents),\n",
    "    \"question\": pergunta,\n",
    "    \"historico\": historico_conversas\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_base_conhecimento = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template=\"\"\"Use o seguinte contexto para responder à pergunta. \n",
    "    Responda apenas com base nas informações fornecidas.\n",
    "    Não forneceça instruções de procedimento já realizados.\n",
    "    Não utilize informações externas ao contexto:\n",
    "    Contexto: {context}\n",
    "    Pergunta: {question}\"\"\"\n",
    ")\n",
    "prompt_historico_conversas = PromptTemplate(\n",
    "    input_variables=[\"historico\", \"question\"],\n",
    "    template=\"\"\"Use o histórico de conversas para responder à pergunta. \n",
    "    Responda apenas com base nas informações fornecidas. \n",
    "    Não forneceça instruções de procedimento já realizados.\n",
    "    Não utilize informações externas ao contexto:\n",
    "    Histórico: {historico}\n",
    "    Pergunta: {question}\"\"\"\n",
    ")\n",
    "prompt_final = PromptTemplate(\n",
    "    input_variables=[\"resposta_base_conhecimento\", \"resposta_historico_conversas\"],\n",
    "    template=\"\"\"Combine as seguintes respostas para gerar uma resposta final,\n",
    "    mas não forneça instruções de procedimentos já realizados:\n",
    "    Resposta da base de conhecimento: {resposta_base_conhecimento}\n",
    "    Resposta do histórico de conversas: {resposta_historico_conversas}\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['context', 'question'] template='Use o seguinte contexto para responder à pergunta. \\n    Responda apenas com base nas informações fornecidas.\\n    Não forneceça instruções de procedimento já realizados.\\n    Não utilize informações externas ao contexto:\\n    Contexto: {context}\\n    Pergunta: {question}'\n"
     ]
    }
   ],
   "source": [
    "print(prompt_base_conhecimento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir as cadeias  \n",
    "chain_base_conhecimento = prompt_base_conhecimento | openai\n",
    "chain_historico_conversas = prompt_historico_conversas | openai\n",
    "chain_final = prompt_final | openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first=PromptTemplate(input_variables=['context', 'question'], template='Use o seguinte contexto para responder à pergunta. \\n    Responda apenas com base nas informações fornecidas.\\n    Não forneceça instruções de procedimento já realizados.\\n    Não utilize informações externas ao contexto:\\n    Contexto: {context}\\n    Pergunta: {question}') last=ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x7f1a30f54350>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x7f1a30f56650>, model_name='gpt-4o', temperature=0.0, openai_api_key=SecretStr('**********'), openai_proxy='')\n"
     ]
    }
   ],
   "source": [
    "print(chain_base_conhecimento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first=PromptTemplate(input_variables=['historico', 'question'], template='Use o histórico de conversas para responder à pergunta. \\n    Responda apenas com base nas informações fornecidas. \\n    Não forneceça instruções de procedimento já realizados.\\n    Não utilize informações externas ao contexto:\\n    Histórico: {historico}\\n    Pergunta: {question}') last=ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x7f1a30f54350>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x7f1a30f56650>, model_name='gpt-4o', temperature=0.0, openai_api_key=SecretStr('**********'), openai_proxy='')\n"
     ]
    }
   ],
   "source": [
    "print(chain_historico_conversas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passando dados e executando\n",
    "resultado_base_conhecimento = chain_base_conhecimento.invoke({\"context\": inputs[\"context\"], \"question\": inputs[\"question\"]})\n",
    "resultado_historico_conversas = chain_historico_conversas.invoke({\"historico\": inputs[\"historico\"], \"question\": inputs[\"question\"]})\n",
    "resultado_final = chain_final.invoke({\"resposta_base_conhecimento\": resultado_base_conhecimento, \n",
    "                                      \"resposta_historico_conversas\": resultado_historico_conversas})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultado Base de Conhecimento:\n",
      " content='Aguarde 30 segundos após conectar a bateria para que o sistema inicialize. Verifique se o interruptor liga/desliga está na posição correta. Se o problema persistir, contate o suporte técnico pelo 0800 555 5555.' response_metadata={'token_usage': {'completion_tokens': 53, 'prompt_tokens': 681, 'total_tokens': 734, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_f5bdcc3276', 'finish_reason': 'stop', 'logprobs': None} id='run-d0203704-dac9-4154-bc6d-2b3e9028e59d-0' usage_metadata={'input_tokens': 681, 'output_tokens': 53, 'total_tokens': 734}\n",
      "----\n",
      "Resultado Histórico de Conversas:\n",
      " content='Pode haver outros problemas, como um fusível queimado ou um problema no interruptor.' response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 106, 'total_tokens': 125, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_d8864f8b6b', 'finish_reason': 'stop', 'logprobs': None} id='run-3eb126d5-52cc-40c6-8b9c-ea312ab2bf9f-0' usage_metadata={'input_tokens': 106, 'output_tokens': 19, 'total_tokens': 125}\n"
     ]
    }
   ],
   "source": [
    "print(\"Resultado Base de Conhecimento:\\n\", resultado_base_conhecimento)\n",
    "print(\"----\")\n",
    "print(\"Resultado Histórico de Conversas:\\n\", resultado_historico_conversas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aguarde 30 segundos após conectar a bateria para que o sistema inicialize. Verifique se o interruptor liga/desliga está na posição correta. Pode haver outros problemas, como um fusível queimado ou um problema no interruptor. Se o problema persistir, contate o suporte técnico pelo 0800 555 5555.\n"
     ]
    }
   ],
   "source": [
    "print(resultado_final.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Aguarde 30 segundos após conectar a bateria para que o sistema inicialize. Verifique se o interruptor liga/desliga está na posição correta. Pode haver outros problemas, como um fusível queimado ou um problema no interruptor. Se o problema persistir, contate o suporte técnico pelo 0800 555 5555.' response_metadata={'token_usage': {'completion_tokens': 71, 'prompt_tokens': 488, 'total_tokens': 559, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_90122d973c', 'finish_reason': 'stop', 'logprobs': None} id='run-a1ac73e5-4705-47e6-8b50-695af0452eef-0' usage_metadata={'input_tokens': 488, 'output_tokens': 71, 'total_tokens': 559}\n"
     ]
    }
   ],
   "source": [
    "print(resultado_final)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
